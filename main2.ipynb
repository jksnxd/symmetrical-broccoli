{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\silve\\Documents\\ex12\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "ds = load_dataset(\"Yelp/yelp_review_full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample = ds['train'].shuffle(seed=42).select(range(1500)).to_pandas()\n",
    "test_sample = ds['test'].shuffle(seed=42).select(range(1500)).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"Positive\", \"Neutral\", \"Negative\"]\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\", device='cuda')\n",
    "\n",
    "def classify_sentiment(review):\n",
    "    prompt = f\"Please label the following Yelp review as Positive, Negative, or Neutral based on the sentiment:\\n\\nReview: \\\"{review}\\\"\\nSentiment:\"\n",
    "    result = classifier(prompt, candidate_labels=labels)\n",
    "    top_label = result['labels'][0]\n",
    "    top_score = result['scores'][0]\n",
    "    return top_label, top_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    }
   ],
   "source": [
    "train_sample[['sentiment', 'score']] = train_sample['text'].apply(lambda x: pd.Series(classify_sentiment(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COT\n",
    "\n",
    "def cot_classify_sentiment(review):\n",
    "    prompt = f\"\"\"\n",
    "    We are given a Yelp review, and we need to determine its sentiment (Positive, Negative, or Neutral). Let's break it down step-by-step:\n",
    "    \n",
    "    Step 1: First, we should check for positive keywords such as \"great,\" \"delicious,\" \"amazing,\" or \"friendly.\"\n",
    "    Step 2: Next, we should check for negative keywords like \"slow,\" \"bad,\" \"dirty,\" or \"unfriendly.\"\n",
    "    Step 3: If the review contains mostly positive words, we will label it as Positive. If it contains negative words, we will label it as Negative. If the review mentions both positive and negative aspects or feels neutral in tone, we will label it as Neutral.\n",
    "    \n",
    "    Review: \"{review}\"\n",
    "    \n",
    "    Based on this reasoning, label the sentiment of the review as one of the following: Positive, Negative, or Neutral.\n",
    "    \n",
    "    Sentiment:\n",
    "    \"\"\"\n",
    "    result = classifier(prompt, candidate_labels=labels)\n",
    "    top_label = result['labels'][0]\n",
    "    top_score = result['scores'][0]\n",
    "    return top_label, top_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample[['cot_sentiment', 'cot_score']] = train_sample['text'].apply(lambda x: pd.Series(cot_classify_sentiment(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cot_sentiment\n",
       "Neutral     1393\n",
       "Positive      85\n",
       "Negative      22\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sample['cot_sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "Negative    717\n",
       "Positive    583\n",
       "Neutral     200\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sample['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing all labels that were placed with a score less than 1/3\n",
    "train_sample = train_sample[(train_sample['score'] >= 0.35)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>score</th>\n",
       "      <th>cot_sentiment</th>\n",
       "      <th>cot_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>I stalk this truck.  I've been to industrial p...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.427783</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.558556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>who really knows if this is good pho or not, i...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.473351</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.602599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>I LOVE Bloom Salon... all of their stylist are...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.720248</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.597057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>We were excited to eat here, it is difficult t...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.492704</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.599148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>So this is a place, with food. That much canno...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.433483</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.658871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>3</td>\n",
       "      <td>Have been going to Pappaduex's off and on for ...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.364719</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.576681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>3</td>\n",
       "      <td>China Chili is not only a 4, it is a very soli...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.756167</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.477633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>4</td>\n",
       "      <td>If you are considering attending the Universit...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.587826</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.473443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>3</td>\n",
       "      <td>So far so good ! I personally did not eat it.....</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.387424</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.636017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>2</td>\n",
       "      <td>We decided to go to Coco's despite the not-so-...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.378851</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.630009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1487 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text sentiment  \\\n",
       "0         4  I stalk this truck.  I've been to industrial p...  Positive   \n",
       "1         2  who really knows if this is good pho or not, i...  Positive   \n",
       "2         4  I LOVE Bloom Salon... all of their stylist are...  Positive   \n",
       "3         0  We were excited to eat here, it is difficult t...  Negative   \n",
       "4         2  So this is a place, with food. That much canno...   Neutral   \n",
       "...     ...                                                ...       ...   \n",
       "1495      3  Have been going to Pappaduex's off and on for ...   Neutral   \n",
       "1496      3  China Chili is not only a 4, it is a very soli...  Positive   \n",
       "1497      4  If you are considering attending the Universit...  Positive   \n",
       "1498      3  So far so good ! I personally did not eat it.....   Neutral   \n",
       "1499      2  We decided to go to Coco's despite the not-so-...  Positive   \n",
       "\n",
       "         score cot_sentiment  cot_score  \n",
       "0     0.427783       Neutral   0.558556  \n",
       "1     0.473351       Neutral   0.602599  \n",
       "2     0.720248       Neutral   0.597057  \n",
       "3     0.492704       Neutral   0.599148  \n",
       "4     0.433483       Neutral   0.658871  \n",
       "...        ...           ...        ...  \n",
       "1495  0.364719       Neutral   0.576681  \n",
       "1496  0.756167       Neutral   0.477633  \n",
       "1497  0.587826       Neutral   0.473443  \n",
       "1498  0.387424       Neutral   0.636017  \n",
       "1499  0.378851       Neutral   0.630009  \n",
       "\n",
       "[1487 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Have been going to Pappaduex's off and on for awhile now.  Seems like I go through spurts where I wind up there several times in a row then not going back for what seems like a year.  That said, this chain is consistently good.  The service is always good, some times better than others but never bad.  \\\\nIt is hard to find good creole and/or cajun food here and while this may not be considered authentic, it is good.  The alligator is lip smackin' good.\\\\nThe atmosphere is somewhat lacking as the acoustics make conversation almost impossible.  Not a good place for a romantic meal, but a good place to have fun with friends.\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sample.loc[1495]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_map = {\n",
    "    'Positive': 2,\n",
    "    'Negative': 1,\n",
    "    'Neutral': 0 \n",
    "}\n",
    "\n",
    "train_sample['sentiment'] = train_sample['sentiment'].map(sentiment_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments, AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], padding='max_length', truncation=True, max_length=512)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample['label'] = train_sample['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "dataset = Dataset.from_pandas(train_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1487/1487 [00:00<00:00, 2497.27 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 61.50ba/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5759439"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset.to_parquet('tokenized_dataset.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
